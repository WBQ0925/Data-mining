# 导入所需库
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix

# 读取数据集
data = pd.read_csv('adult.csv')

# 数据预处理
data = data.replace(' ?', pd.np.nan)  # 将' ?'替换为缺失值
mode = data.mode().iloc[0]  # 计算众数
data = data.fillna(mode)  # 用众数填充缺失值
le = LabelEncoder()
for col in data.columns:
    if data[col].dtype == 'object':
        data[col] = le.fit_transform(data[col])

# 特征工程
y = data['income']
X = data.drop(['income'], axis=1)
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 变量筛选
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
skb = SelectKBest(score_func=chi2)
acc_list = []
for k in range(1, X.shape[1]+1):
    X_new = skb.fit_transform(X, y)
    acc_fold = []
    for train_idx, test_idx in kfold.split(X_new, y):
        X_train, X_test = X_new[train_idx], X_new[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        lr = LogisticRegression()
        lr.fit(X_train, y_train)
        y_pred = lr.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        acc_fold.append(acc)
    acc_list.append(np.mean(acc_fold))
best_k = np.argmax(acc_list) + 1
print("Best number of features:", best_k)

# 选取最佳变量
X_new = skb.fit_transform(X, y)
X_new = X_new[:, skb.get_support(indices=True)]

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

# 逻辑回归模型
lr = LogisticRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
acc_lr = accuracy_score(y_test, y_pred_lr)
cm_lr = confusion_matrix(y_test, y_pred_lr)
print("Accuracy of Logistic Regression:", acc_lr)
print("Confusion Matrix of Logistic Regression:")
print(cm_lr)

# 决策树模型
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
acc_dt = accuracy_score(y_test, y_pred_dt)
cm_dt = confusion_matrix(y_test, y_pred_dt)
print("Accuracy of Decision Tree:", acc_dt)
print("Confusion Matrix of Decision Tree:")
print(cm_dt)

# 随机森林模型
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
acc_rf = accuracy_score(y_test, y_pred_rf)
cm_rf = confusion_matrix(y_test, y_pred_rf)
print("Accuracy of Random Forest:", acc_rf)
print("Confusion Matrix of Random Forest:")
print(cm_rf)

# Adaboost模型
ada = AdaBoostClassifier()
ada.fit(X_train, y_train)
y_pred_ada = ada.predict(X_test)
acc_ada = accuracy_score(y_test, y_pred_ada)
cm_ada = confusion_matrix(y_test, y_pred_ada)
print("Accuracy of AdaBoost:", acc_ada)
print("Confusion Matrix of AdaBoost:")
print(cm_ada)

# XGBoost模型
xgb = XGBClassifier()
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
acc_xgb = accuracy_score(y_test, y_pred_xgb)
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
print("Accuracy of XGBoost:", acc_xgb)
print("Confusion Matrix of XGBoost:")
print(cm_xgb)

# SVM模型
svm = SVC()
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)
acc_svm = accuracy_score(y_test, y_pred_svm)
cm_svm = confusion_matrix(y_test, y_pred_svm)
print("Accuracy of SVM:", acc_svm)
print("Confusion Matrix of SVM:")
print(cm_svm)

# 朴素贝叶斯模型
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred_nb = nb.predict(X_test)
acc_nb = accuracy_score(y_test, y_pred_nb)
cm_nb = confusion_matrix(y_test, y_pred_nb)
print("Accuracy of Naive Bayes:", acc_nb)
print("Confusion Matrix of Naive Bayes:")
print(cm_nb)